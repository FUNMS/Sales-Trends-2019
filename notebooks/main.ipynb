{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Maximizing Revenue with Data: 2019 Sales Trends and Product Performance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Business Understanding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Problem Satement**\n",
    "\n",
    "A client assigned by getINNOtized, has collected transactional data for the year 2019 but hasn't been able to effectively use this data to improve sales or operational efficiency. They need insights into sales performance, seasonal trends, product popularity, and city-level sales to help drive more sales and streamline operations.\n",
    "\n",
    "#### **Goal and Objectives**\n",
    "\n",
    "The main goal is to deliver a comprehensive business intelligence (BI) solution that helps the client:\n",
    "\n",
    "- Identify trends and seasonality in sales.\n",
    "- Analyze product performance to discover best- and worst-selling items.\n",
    "- Compare sales across different time periods (monthly, weekly) for actionable insights.\n",
    "- Analyze geographical sales performance to identify cities with higher demand.\n",
    "- Segment products based on price and analyze their contribution to total sales.\n",
    "\n",
    "\n",
    "#### **Stakeholders**\n",
    "- Primary Stakeholders: Management team looking for sales and operational insights.\n",
    "- Secondary Stakeholders: Sales and marketing teams who can use the insights for future campaigns.\n",
    "- Analysts: Those responsible for deriving and communicating actionable insights.\n",
    "- Operations Team: Can leverage insights for improving efficiency in delivering products to high-demand areas.\n",
    "\n",
    "#### **Key Metrics and Success**\n",
    "- Total Sales Revenue: Monthly and yearly revenue.\n",
    "- Seasonality Metrics: Monthly/quarterly sales trends.\n",
    "- Product Performance: Revenue and quantity sold by product.\n",
    "- Geographic Metrics: Sales distribution by city.\n",
    "- Product Category Performance: Revenue and quantity sold by product category (high-level vs. basic).\n",
    "- Operational Efficiency: Timeliness of reporting, ease of extracting actionable insights, and ability to identify growth   opportunities\n",
    "\n",
    "#### **Hypotheses**\n",
    "Null Hypothesis (H0): There is no significant seasonality in sales across the year.\n",
    "\n",
    "Alternate Hypothesis (H1): There is significant seasonality in sales, with certain months showing higher or lower sales trends\n",
    "\n",
    "#### **Features**\n",
    "1. Order ID: Identifies each sales transaction.\n",
    "2. Product: Specifies the product sold.\n",
    "3. Quantity Ordered: Represents the number of units ordered.\n",
    "4. Price Each: Indicates the price per unit of the product.\n",
    "5. Order Date: The date when the order was placed.\n",
    "6. Purchase Address: The shipping or billing address associated with the order.\n",
    "\n",
    "#### **Methodology** \n",
    "The project follows the CRISP-DM (Cross Industry Standard Process for Data Mining) methodology, structured as: \n",
    "- Business Understanding: Define objectives and requirements from the client to drive sales and improve efficiency\n",
    "- Data Understanding: Collect and explore the dataset, which includes sales data for 2019 across various columns\n",
    "- Data Preparation: Clean and transform the data, integrating sources from CSV files and a remote database\n",
    "- Modelling: Apply appropriate data analysis techniques to uncover insights.\n",
    "- Evaluation: Assess the results against business objectives to ensure they meet the clientâ€™s needs\n",
    "- Deployment: Develop and deploy a Power BI dashboard to visualize the insights\n",
    "\n",
    "#### **Analytical Questions**\n",
    "1. How much money did we make this year? \n",
    "\n",
    "2. Can we identify any seasonality in the sales? \n",
    "\n",
    "3. What are our best and worst-selling products? \n",
    "\n",
    "4. How do sales compare to previous months or weeks? \n",
    "\n",
    "5. Which cities are our products delivered to most? \n",
    "\n",
    "6. How do product categories compare in revenue generated and quantities ordered? \n",
    "\n",
    "#### **Scope and Constraints**\n",
    "Scope:\n",
    "- Analysis will focus on the sales data for 2019, broken down by months, weeks, and product categories.\n",
    "- Sales data for January to June will be extracted from CSV files, and data for July to December will be pulled from the database.\n",
    "- The analysis will also involve comparison between high-level and basic products based on unit price thresholds.\n",
    "\n",
    "Constraints:\n",
    "- Data integration: Combining two different data sources (CSV and database).\n",
    "- Time constraints for accessing, cleaning, and preparing the data.\n",
    "- Potential inconsistencies in data formatting between the first and second halves of the year.\n",
    "\n",
    "\n",
    "#### **Extra Information**\n",
    "- The products with a unit price greater than $99.99 will be categorized as high-level products, and those below or equal to $99.99 will be considered basic products. This categorization will be critical for revenue comparisons across product types.\n",
    "- To answer the questions efficiently, a blend of SQL for database querying and Python/Excel for data analysis and visualization will be required.\n",
    "- This project must be completed in two weeks \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Understanding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Importation of libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import dotenv_values\n",
    "import os\n",
    "\n",
    "# Managing environment variables\n",
    "#from dotenv import dotenv_values\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    " \n",
    "# Database connectivity\n",
    "import pyodbc\n",
    " \n",
    "# Database ORM\n",
    "from sqlalchemy import create_engine\n",
    " \n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    " \n",
    "\n",
    "# Machine learning \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of January Data:\n",
      "  Order ID                   Product Quantity Ordered Price Each  \\\n",
      "0   141234                    iPhone                1        700   \n",
      "1   141235  Lightning Charging Cable                1      14.95   \n",
      "2   141236          Wired Headphones                2      11.99   \n",
      "3   141237          27in FHD Monitor                1     149.99   \n",
      "4   141238          Wired Headphones                1      11.99   \n",
      "\n",
      "       Order Date                       Purchase Address  \n",
      "0  01/22/19 21:25        944 Walnut St, Boston, MA 02215  \n",
      "1  01/28/19 14:15       185 Maple St, Portland, OR 97035  \n",
      "2  01/17/19 13:33  538 Adams St, San Francisco, CA 94016  \n",
      "3  01/05/19 20:33     738 10th St, Los Angeles, CA 90001  \n",
      "4  01/25/19 11:59          387 10th St, Austin, TX 73301  \n",
      "\n",
      "\n",
      "Head of February Data:\n",
      "  Order ID                   Product Quantity Ordered Price Each  \\\n",
      "0   150502                    iPhone                1        700   \n",
      "1   150503     AA Batteries (4-pack)                1       3.84   \n",
      "2   150504    27in 4K Gaming Monitor                1     389.99   \n",
      "3   150505  Lightning Charging Cable                1      14.95   \n",
      "4   150506     AA Batteries (4-pack)                2       3.84   \n",
      "\n",
      "       Order Date                     Purchase Address  \n",
      "0  02/18/19 01:35    866 Spruce St, Portland, ME 04101  \n",
      "1  02/13/19 07:24  18 13th St, San Francisco, CA 94016  \n",
      "2  02/18/19 09:46   52 6th St, New York City, NY 10001  \n",
      "3  02/02/19 16:47     129 Cherry St, Atlanta, GA 30301  \n",
      "4  02/28/19 20:32    548 Lincoln St, Seattle, WA 98101  \n",
      "\n",
      "\n",
      "Head of March Data:\n",
      "  Order ID                     Product Quantity Ordered Price Each  \\\n",
      "0   162009                      iPhone                1        700   \n",
      "1   162009    Lightning Charging Cable                1      14.95   \n",
      "2   162009            Wired Headphones                2      11.99   \n",
      "3   162010  Bose SoundSport Headphones                1      99.99   \n",
      "4   162011      34in Ultrawide Monitor                1     379.99   \n",
      "\n",
      "       Order Date                      Purchase Address  \n",
      "0  03/28/19 20:59       942 Church St, Austin, TX 73301  \n",
      "1  03/28/19 20:59       942 Church St, Austin, TX 73301  \n",
      "2  03/28/19 20:59       942 Church St, Austin, TX 73301  \n",
      "3  03/17/19 05:39  261 10th St, San Francisco, CA 94016  \n",
      "4  03/10/19 00:01  764 13th St, San Francisco, CA 94016  \n",
      "\n",
      "\n",
      "Head of April Data:\n",
      "  Order ID                     Product Quantity Ordered Price Each  \\\n",
      "0   176558        USB-C Charging Cable                2      11.95   \n",
      "1      NaN                         NaN              NaN        NaN   \n",
      "2   176559  Bose SoundSport Headphones                1      99.99   \n",
      "3   176560                Google Phone                1        600   \n",
      "4   176560            Wired Headphones                1      11.99   \n",
      "\n",
      "       Order Date                      Purchase Address  \n",
      "0  04/19/19 08:46          917 1st St, Dallas, TX 75001  \n",
      "1             NaN                                   NaN  \n",
      "2  04/07/19 22:30     682 Chestnut St, Boston, MA 02215  \n",
      "3  04/12/19 14:38  669 Spruce St, Los Angeles, CA 90001  \n",
      "4  04/12/19 14:38  669 Spruce St, Los Angeles, CA 90001  \n",
      "\n",
      "\n",
      "Head of May Data:\n",
      "  Order ID                 Product Quantity Ordered Price Each  \\\n",
      "0   194095        Wired Headphones                1      11.99   \n",
      "1   194096   AA Batteries (4-pack)                1       3.84   \n",
      "2   194097        27in FHD Monitor                1     149.99   \n",
      "3   194098        Wired Headphones                1      11.99   \n",
      "4   194099  AAA Batteries (4-pack)                2       2.99   \n",
      "\n",
      "       Order Date                         Purchase Address  \n",
      "0  05/16/19 17:14      669 2nd St, New York City, NY 10001  \n",
      "1  05/19/19 14:43          844 Walnut St, Dallas, TX 75001  \n",
      "2  05/24/19 11:36  164 Madison St, New York City, NY 10001  \n",
      "3  05/02/19 20:40          622 Meadow St, Dallas, TX 75001  \n",
      "4  05/11/19 22:55          17 Church St, Seattle, WA 98101  \n",
      "\n",
      "\n",
      "Head of June Data:\n",
      "  Order ID                     Product Quantity Ordered Price Each  \\\n",
      "0   209921        USB-C Charging Cable                1      11.95   \n",
      "1   209922          Macbook Pro Laptop                1     1700.0   \n",
      "2   209923             ThinkPad Laptop                1     999.99   \n",
      "3   209924            27in FHD Monitor                1     149.99   \n",
      "4   209925  Bose SoundSport Headphones                1      99.99   \n",
      "\n",
      "       Order Date                       Purchase Address  \n",
      "0  06/23/19 19:34      950 Walnut St, Portland, ME 04101  \n",
      "1  06/30/19 10:05     80 4th St, San Francisco, CA 94016  \n",
      "2  06/24/19 20:18  402 Jackson St, Los Angeles, CA 90001  \n",
      "3  06/05/19 10:21         560 10th St, Seattle, WA 98101  \n",
      "4  06/25/19 18:58    545 2nd St, San Francisco, CA 94016  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Loading Data from January to June\n",
    "# List of CSV files (January to June)\n",
    "csv_files = ['Sales_January_2019.csv', 'Sales_February_2019.csv', 'Sales_March_2019.csv', \n",
    "             'Sales_April_2019.csv', 'Sales_May_2019.csv', 'Sales_June_2019.csv']  \n",
    "\n",
    "# Define the folder path\n",
    "folder_path = r'C:\\Users\\USER\\Desktop\\Sales-Trends-2019\\data'  \n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "df_firsthalf = []  \n",
    "\n",
    "# Loop over the CSV files to load each into a DataFrame and append to list\n",
    "for file in csv_files:\n",
    "    # Correctly join the folder path and file name\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    \n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Append the DataFrame to the list\n",
    "    df_firsthalf.append(df)\n",
    "    \n",
    "    # Print the head of the DataFrame for each month for verification\n",
    "    print(f\"Head of {file.split('_')[1]} Data:\")\n",
    "    print(df.head())  \n",
    "    print(\"\\n\")  # Add a line break for readability\n",
    "\n",
    "# Now firsthalf_dataframes contains all the DataFrames for January to June\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to dapDB successful!\n",
      "Fetching data from Sales_July_2019...\n",
      "   Order_ID                   Product  Quantity_Ordered  Price_Each  \\\n",
      "0  222910.0  Apple Airpods Headphones               1.0      150.00   \n",
      "1  222911.0             Flatscreen TV               1.0      300.00   \n",
      "2  222912.0     AA Batteries (4-pack)               1.0        3.84   \n",
      "3  222913.0     AA Batteries (4-pack)               1.0        3.84   \n",
      "4  222914.0    AAA Batteries (4-pack)               5.0        2.99   \n",
      "\n",
      "           Order_Date                  Purchase_Address  \n",
      "0 2026-07-19 16:51:00   389 South St, Atlanta, GA 30301  \n",
      "1 2005-07-19 08:55:00     590 4th St, Seattle, WA 98101  \n",
      "2 2029-07-19 12:41:00    861 Hill St, Atlanta, GA 30301  \n",
      "3 2028-07-19 10:15:00   190 Ridge St, Atlanta, GA 30301  \n",
      "4 2031-07-19 02:13:00  824 Forest St, Seattle, WA 98101  \n",
      "Data from Sales_July_2019 saved to Sales_July_2019.csv\n",
      "Fetching data from Sales_August_2019...\n",
      "   Order_ID                     Product  Quantity_Ordered  Price_Each  \\\n",
      "0  236670.0            Wired Headphones               2.0   11.990000   \n",
      "1  236671.0  Bose SoundSport Headphones               1.0   99.989998   \n",
      "2  236672.0                      iPhone               1.0  700.000000   \n",
      "3  236673.0       AA Batteries (4-pack)               2.0    3.840000   \n",
      "4  236674.0       AA Batteries (4-pack)               2.0    3.840000   \n",
      "\n",
      "           Order_Date                      Purchase_Address  \n",
      "0 2031-08-19 22:21:00      359 Spruce St, Seattle, WA 98101  \n",
      "1 2015-08-19 15:11:00        492 Ridge St, Dallas, TX 75001  \n",
      "2 2006-08-19 14:40:00        149 7th St, Portland, OR 97035  \n",
      "3 2029-08-19 20:59:00     631 2nd St, Los Angeles, CA 90001  \n",
      "4 2015-08-19 19:53:00  736 14th St, New York City, NY 10001  \n",
      "Data from Sales_August_2019 saved to Sales_August_2019.csv\n",
      "Fetching data from Sales_September_2019...\n",
      "   Order_ID                Product  Quantity_Ordered  Price_Each  \\\n",
      "0  248151.0  AA Batteries (4-pack)               4.0    3.840000   \n",
      "1  248152.0   USB-C Charging Cable               2.0   11.950000   \n",
      "2  248153.0   USB-C Charging Cable               1.0   11.950000   \n",
      "3  248154.0       27in FHD Monitor               1.0  149.990005   \n",
      "4  248155.0   USB-C Charging Cable               1.0   11.950000   \n",
      "\n",
      "           Order_Date                       Purchase_Address  \n",
      "0 2017-09-19 14:44:00    380 North St, Los Angeles, CA 90001  \n",
      "1 2029-09-19 10:19:00           511 8th St, Austin, TX 73301  \n",
      "2 2016-09-19 17:48:00  151 Johnson St, Los Angeles, CA 90001  \n",
      "3 2027-09-19 07:52:00      355 Hickory St, Seattle, WA 98101  \n",
      "4 2001-09-19 19:03:00          125 5th St, Atlanta, GA 30301  \n",
      "Data from Sales_September_2019 saved to Sales_September_2019.csv\n",
      "Fetching data from Sales_October_2019...\n",
      "   Order_ID                 Product  Quantity_Ordered  Price_Each  \\\n",
      "0  259358.0  34in Ultrawide Monitor               1.0  379.989990   \n",
      "1  259359.0  27in 4K Gaming Monitor               1.0  389.989990   \n",
      "2  259360.0  AAA Batteries (4-pack)               2.0    2.990000   \n",
      "3  259361.0        27in FHD Monitor               1.0  149.990005   \n",
      "4  259362.0        Wired Headphones               1.0   11.990000   \n",
      "\n",
      "           Order_Date                           Purchase_Address  \n",
      "0 2028-10-19 10:56:00            609 Cherry St, Dallas, TX 75001  \n",
      "1 2028-10-19 17:26:00          225 5th St, Los Angeles, CA 90001  \n",
      "2 2024-10-19 17:20:00       967 12th St, New York City, NY 10001  \n",
      "3 2014-10-19 22:26:00  628 Jefferson St, New York City, NY 10001  \n",
      "4 2007-10-19 16:10:00         534 14th St, Los Angeles, CA 90001  \n",
      "Data from Sales_October_2019 saved to Sales_October_2019.csv\n",
      "Fetching data from Sales_November_2019...\n",
      "   Order_ID                     Product  Quantity_Ordered  Price_Each  \\\n",
      "0  278797.0            Wired Headphones               1.0   11.990000   \n",
      "1  278798.0        USB-C Charging Cable               2.0   11.950000   \n",
      "2  278799.0    Apple Airpods Headphones               1.0  150.000000   \n",
      "3  278800.0            27in FHD Monitor               1.0  149.990005   \n",
      "4  278801.0  Bose SoundSport Headphones               1.0   99.989998   \n",
      "\n",
      "           Order_Date                      Purchase_Address  \n",
      "0 2021-11-19 09:54:00   46 Park St, New York City, NY 10001  \n",
      "1 2017-11-19 10:03:00      962 Hickory St, Austin, TX 73301  \n",
      "2 2019-11-19 14:56:00  464 Cherry St, Los Angeles, CA 90001  \n",
      "3 2025-11-19 22:24:00        649 10th St, Seattle, WA 98101  \n",
      "4 2009-11-19 13:56:00         522 Hill St, Boston, MA 02215  \n",
      "Data from Sales_November_2019 saved to Sales_November_2019.csv\n",
      "Fetching data from Sales_December_2019...\n",
      "   Order_ID               Product  Quantity_Ordered   Price_Each  \\\n",
      "0  295665.0    Macbook Pro Laptop               1.0  1700.000000   \n",
      "1  295666.0    LG Washing Machine               1.0   600.000000   \n",
      "2  295667.0  USB-C Charging Cable               1.0    11.950000   \n",
      "3  295668.0      27in FHD Monitor               1.0   149.990005   \n",
      "4  295669.0  USB-C Charging Cable               1.0    11.950000   \n",
      "\n",
      "           Order_Date                        Purchase_Address  \n",
      "0 2030-12-19 00:01:00  136 Church St, New York City, NY 10001  \n",
      "1 2029-12-19 07:03:00     562 2nd St, New York City, NY 10001  \n",
      "2 2012-12-19 18:21:00    277 Main St, New York City, NY 10001  \n",
      "3 2022-12-19 15:13:00     410 6th St, San Francisco, CA 94016  \n",
      "4 2018-12-19 12:38:00           43 Hill St, Atlanta, GA 30301  \n",
      "Data from Sales_December_2019 saved to Sales_December_2019.csv\n"
     ]
    }
   ],
   "source": [
    "# Loading Data from July to December\n",
    "\n",
    "# Define the connection string\n",
    "connection_string = (\n",
    "    'DRIVER={ODBC Driver 17 for SQL Server};'\n",
    "    'SERVER=dap-projects-database.database.windows.net;'\n",
    "    'DATABASE=dapDB;'\n",
    "    'UID=capstone;'\n",
    "    'PWD=Z7x@8pM$2w;'\n",
    ")\n",
    "\n",
    "# Connect to the SQL Server database\n",
    "try:\n",
    "    connection = pyodbc.connect(connection_string)\n",
    "    print(\"Connection to dapDB successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to the database: {e}\")\n",
    "    exit()\n",
    "\n",
    "# List of table names \n",
    "table_names = ['Sales_July_2019', 'Sales_August_2019', 'Sales_September_2019',\n",
    "               'Sales_October_2019', 'Sales_November_2019', 'Sales_December_2019']\n",
    "\n",
    "# Create an empty list to store DataFrames\n",
    "df_secondhalf = []\n",
    "\n",
    "# Loop through each table and fetch data\n",
    "for table in table_names:\n",
    "    print(f\"Fetching data from {table}...\")\n",
    "    query = f\"SELECT * FROM {table}\"  # SQL query to select all data from the table\n",
    "    \n",
    "    # Fetch the data into a Pandas DataFrame\n",
    "    df = pd.read_sql(query, connection)\n",
    "    \n",
    "    # Display the first few rows \n",
    "    print(df.head())\n",
    "    \n",
    "    # Save the data to a CSV file \n",
    "    csv_filename = f\"{table}.csv\"\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "    print(f\"Data from {table} saved to {csv_filename}\")\n",
    "    \n",
    "    # Append the DataFrame to the list\n",
    "    df_secondhalf.append(df)\n",
    "\n",
    "\n",
    "\n",
    "# Close the connection\n",
    "connection.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Insights**\n",
    "- The datasets retrieved from the one drive are placed in the variable firsthalf and the datasets retrieved from the remote database are in the vaaible secondhalf \n",
    "\n",
    "- Column headings accross both datasets are similar but not the same eg. Order ID and Order_ID \n",
    "\n",
    "- Order_Date column for the secondhalf dataset needs thorough cleaning. \n",
    "\n",
    "- There are variety of products which affect significant price range in the data, from items priced as low as $2.99 (batteries) to as high as $1,700 (Macbook Pro Laptop).\n",
    "\n",
    "- Products with unit prices above $99.99 should be labeled high-level products otherwise they should be basic level\n",
    "\n",
    "- Most orders seem to involve single units of high-cost items (e.g., iPhone or Flatscreen TV), but for low-cost items like cables and batteries, customers are purchasing multiple units per order.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **EDA & Data Cleaning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Firsthalf Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Order ID                   Product Quantity Ordered Price Each  \\\n",
      "0   141234                    iPhone                1        700   \n",
      "1   141235  Lightning Charging Cable                1      14.95   \n",
      "2   141236          Wired Headphones                2      11.99   \n",
      "3   141237          27in FHD Monitor                1     149.99   \n",
      "4   141238          Wired Headphones                1      11.99   \n",
      "\n",
      "       Order Date                       Purchase Address  \n",
      "0  01/22/19 21:25        944 Walnut St, Boston, MA 02215  \n",
      "1  01/28/19 14:15       185 Maple St, Portland, OR 97035  \n",
      "2  01/17/19 13:33  538 Adams St, San Francisco, CA 94016  \n",
      "3  01/05/19 20:33     738 10th St, Los Angeles, CA 90001  \n",
      "4  01/25/19 11:59          387 10th St, Austin, TX 73301  \n"
     ]
    }
   ],
   "source": [
    "# Concatenate all the DataFrames in df_firsthalf\n",
    "firsthalf_combined = pd.concat(df_firsthalf, ignore_index=True)\n",
    "print(firsthalf_combined.head())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 85625 entries, 0 to 85624\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Order ID          85380 non-null  object\n",
      " 1   Product           85380 non-null  object\n",
      " 2   Quantity Ordered  85380 non-null  object\n",
      " 3   Price Each        85380 non-null  object\n",
      " 4   Order Date        85380 non-null  object\n",
      " 5   Purchase Address  85380 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 3.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Product</th>\n",
       "      <th>Quantity Ordered</th>\n",
       "      <th>Price Each</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Purchase Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141234</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>1</td>\n",
       "      <td>700</td>\n",
       "      <td>01/22/19 21:25</td>\n",
       "      <td>944 Walnut St, Boston, MA 02215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>141235</td>\n",
       "      <td>Lightning Charging Cable</td>\n",
       "      <td>1</td>\n",
       "      <td>14.95</td>\n",
       "      <td>01/28/19 14:15</td>\n",
       "      <td>185 Maple St, Portland, OR 97035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>141236</td>\n",
       "      <td>Wired Headphones</td>\n",
       "      <td>2</td>\n",
       "      <td>11.99</td>\n",
       "      <td>01/17/19 13:33</td>\n",
       "      <td>538 Adams St, San Francisco, CA 94016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>141237</td>\n",
       "      <td>27in FHD Monitor</td>\n",
       "      <td>1</td>\n",
       "      <td>149.99</td>\n",
       "      <td>01/05/19 20:33</td>\n",
       "      <td>738 10th St, Los Angeles, CA 90001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>141238</td>\n",
       "      <td>Wired Headphones</td>\n",
       "      <td>1</td>\n",
       "      <td>11.99</td>\n",
       "      <td>01/25/19 11:59</td>\n",
       "      <td>387 10th St, Austin, TX 73301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Order ID                   Product Quantity Ordered Price Each  \\\n",
       "0   141234                    iPhone                1        700   \n",
       "1   141235  Lightning Charging Cable                1      14.95   \n",
       "2   141236          Wired Headphones                2      11.99   \n",
       "3   141237          27in FHD Monitor                1     149.99   \n",
       "4   141238          Wired Headphones                1      11.99   \n",
       "\n",
       "       Order Date                       Purchase Address  \n",
       "0  01/22/19 21:25        944 Walnut St, Boston, MA 02215  \n",
       "1  01/28/19 14:15       185 Maple St, Portland, OR 97035  \n",
       "2  01/17/19 13:33  538 Adams St, San Francisco, CA 94016  \n",
       "3  01/05/19 20:33     738 10th St, Los Angeles, CA 90001  \n",
       "4  01/25/19 11:59          387 10th St, Austin, TX 73301  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check shape of firsthalf_combined\n",
    "firsthalf_combined.shape\n",
    "\n",
    "#Check info of firsthalf_combined \n",
    "firsthalf_combined.info()\n",
    "\n",
    "#Check for first rows of heading\n",
    "firsthalf_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order ID            81677\n",
      "Product                20\n",
      "Quantity Ordered        9\n",
      "Price Each             23\n",
      "Order Date          66474\n",
      "Purchase Address    72960\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "unique_counts = firsthalf_combined.nunique()\n",
    "print(unique_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Product</th>\n",
       "      <th>Quantity Ordered</th>\n",
       "      <th>Price Each</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Purchase Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>85380</td>\n",
       "      <td>85380</td>\n",
       "      <td>85380</td>\n",
       "      <td>85380</td>\n",
       "      <td>85380</td>\n",
       "      <td>85380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>81677</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>66474</td>\n",
       "      <td>72960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Order ID</td>\n",
       "      <td>USB-C Charging Cable</td>\n",
       "      <td>1</td>\n",
       "      <td>11.95</td>\n",
       "      <td>Order Date</td>\n",
       "      <td>Purchase Address</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>160</td>\n",
       "      <td>9952</td>\n",
       "      <td>77205</td>\n",
       "      <td>9952</td>\n",
       "      <td>160</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Order ID               Product Quantity Ordered Price Each  \\\n",
       "count      85380                 85380            85380      85380   \n",
       "unique     81677                    20                9         23   \n",
       "top     Order ID  USB-C Charging Cable                1      11.95   \n",
       "freq         160                  9952            77205       9952   \n",
       "\n",
       "        Order Date  Purchase Address  \n",
       "count        85380             85380  \n",
       "unique       66474             72960  \n",
       "top     Order Date  Purchase Address  \n",
       "freq           160               160  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Describe firsthalf_combined \n",
    "firsthalf_combined.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order ID            245\n",
      "Product             245\n",
      "Quantity Ordered    245\n",
      "Price Each          245\n",
      "Order Date          245\n",
      "Purchase Address    245\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the first half data\n",
    "print(firsthalf_combined.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Insights of firsthalf_combined**\n",
    "- The first half combined data has a total of  101225 and 6 columns\n",
    "\n",
    "- The columns `Quantity Ordered`, `Price Each`, and `Order Date` will need conversion into appropriate data types (e.g., integer, float, datetime) for further analysis.\n",
    "\n",
    "- The unique values gives a lot of insight about the data especially in dealing with duplicates in the `Order ID` column\n",
    "\n",
    "- 245 rows are completely missing values across all columns, which indicates incomplete transactions or errors during data entry.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Data Exploring and Cleaning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order ID            0\n",
      "Product             0\n",
      "Quantity Ordered    0\n",
      "Price Each          0\n",
      "Order Date          0\n",
      "Purchase Address    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with any missing values and assign the result to a new variable\n",
    "firsthalf_cleaned = firsthalf_combined.dropna(how='any')\n",
    "\n",
    "# Verify no more missing values\n",
    "print(firsthalf_cleaned.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates in 'Order ID': 85380\n",
      "Full row duplicates: 81677\n",
      "\n",
      "Missing values in each column:\n",
      " Order ID            0\n",
      "Product             0\n",
      "Quantity Ordered    0\n",
      "Price Each          0\n",
      "Order Date          0\n",
      "Purchase Address    0\n",
      "dtype: int64\n",
      "\n",
      "Data structure after cleanup:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 81677 entries, 0 to 85624\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Order ID          81677 non-null  object\n",
      " 1   Product           81677 non-null  object\n",
      " 2   Quantity Ordered  81677 non-null  object\n",
      " 3   Price Each        81677 non-null  object\n",
      " 4   Order Date        81677 non-null  object\n",
      " 5   Purchase Address  81677 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 4.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Check and remove duplicates in 'Order ID' and full rows\n",
    "\n",
    "# Check and remove duplicates in 'Order ID'\n",
    "firsthalf_cleaned[firsthalf_cleaned.duplicated(subset='Order ID', keep=False)]\n",
    "print(f\"Duplicates in 'Order ID': {len(firsthalf_cleaned)}\")\n",
    "\n",
    "# Drop duplicates in 'Order ID', keep first occurrence\n",
    "firsthalf_cleaned = firsthalf_cleaned.drop_duplicates(subset='Order ID', keep='first')\n",
    "\n",
    "# Check and remove full-row duplicates\n",
    "firsthalf_cleaned[firsthalf_cleaned.duplicated(keep=False)]\n",
    "print(f\"Full row duplicates: {len(firsthalf_cleaned)}\")\n",
    "\n",
    "# Drop full-row duplicates\n",
    "firsthalf_cleaned = firsthalf_cleaned.drop_duplicates(keep='first')\n",
    "\n",
    "# Recheck missing values in each column\n",
    "missing_values = firsthalf_cleaned.isnull().sum()\n",
    "print(\"\\nMissing values in each column:\\n\", missing_values)\n",
    "\n",
    "# Final check of data structure and types\n",
    "print(\"\\nData structure after cleanup:\")\n",
    "print(firsthalf_cleaned.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 81677 entries, 0 to 85624\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   Order ID          81676 non-null  Int64         \n",
      " 1   Product           81677 non-null  object        \n",
      " 2   Quantity Ordered  81676 non-null  Int64         \n",
      " 3   Price Each        81676 non-null  float64       \n",
      " 4   Order Date        81676 non-null  datetime64[ns]\n",
      " 5   Purchase Address  81677 non-null  object        \n",
      "dtypes: Int64(2), datetime64[ns](1), float64(1), object(2)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "#Correction of datatypes\n",
    "\n",
    "# Convert 'Order ID' to integer\n",
    "firsthalf_cleaned['Order ID'] = pd.to_numeric(firsthalf_cleaned['Order ID'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Convert 'Quantity Ordered' to integer\n",
    "firsthalf_cleaned['Quantity Ordered'] = pd.to_numeric(firsthalf_cleaned['Quantity Ordered'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Convert 'Price Each' to float\n",
    "firsthalf_cleaned['Price Each'] = pd.to_numeric(firsthalf_cleaned['Price Each'], errors='coerce').astype(float)\n",
    "\n",
    "# Convert 'Order Date' to datetime format\n",
    "firsthalf_cleaned['Order Date'] = pd.to_datetime(firsthalf_cleaned['Order Date'], errors='coerce')\n",
    "\n",
    "# Verify the data types after conversion\n",
    "firsthalf_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81677, 6)\n",
      "   Order ID                   Product  Quantity Ordered  Price Each  \\\n",
      "0    141234                    iPhone                 1      700.00   \n",
      "1    141235  Lightning Charging Cable                 1       14.95   \n",
      "2    141236          Wired Headphones                 2       11.99   \n",
      "3    141237          27in FHD Monitor                 1      149.99   \n",
      "4    141238          Wired Headphones                 1       11.99   \n",
      "\n",
      "           Order Date                       Purchase Address  \n",
      "0 2019-01-22 21:25:00        944 Walnut St, Boston, MA 02215  \n",
      "1 2019-01-28 14:15:00       185 Maple St, Portland, OR 97035  \n",
      "2 2019-01-17 13:33:00  538 Adams St, San Francisco, CA 94016  \n",
      "3 2019-01-05 20:33:00     738 10th St, Los Angeles, CA 90001  \n",
      "4 2019-01-25 11:59:00          387 10th St, Austin, TX 73301  \n"
     ]
    }
   ],
   "source": [
    "# Check the shape of the cleaned data\n",
    "print(firsthalf_cleaned.shape)\n",
    "\n",
    "# Print the first few rows of the cleaned dataset\n",
    "print(firsthalf_cleaned.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Secondhalf Data Understanding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Order_ID                   Product  Quantity_Ordered  Price_Each  \\\n",
      "0  222910.0  Apple Airpods Headphones               1.0      150.00   \n",
      "1  222911.0             Flatscreen TV               1.0      300.00   \n",
      "2  222912.0     AA Batteries (4-pack)               1.0        3.84   \n",
      "3  222913.0     AA Batteries (4-pack)               1.0        3.84   \n",
      "4  222914.0    AAA Batteries (4-pack)               5.0        2.99   \n",
      "\n",
      "           Order_Date                  Purchase_Address  \n",
      "0 2026-07-19 16:51:00   389 South St, Atlanta, GA 30301  \n",
      "1 2005-07-19 08:55:00     590 4th St, Seattle, WA 98101  \n",
      "2 2029-07-19 12:41:00    861 Hill St, Atlanta, GA 30301  \n",
      "3 2028-07-19 10:15:00   190 Ridge St, Atlanta, GA 30301  \n",
      "4 2031-07-19 02:13:00  824 Forest St, Seattle, WA 98101  \n"
     ]
    }
   ],
   "source": [
    "# Combine the second half of the year into one DataFrame\n",
    "secondhalf_combined = pd.concat(df_secondhalf, ignore_index=True)\n",
    "print(secondhalf_combined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101225 entries, 0 to 101224\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count   Dtype         \n",
      "---  ------            --------------   -----         \n",
      " 0   Order_ID          100730 non-null  float64       \n",
      " 1   Product           100925 non-null  object        \n",
      " 2   Quantity_Ordered  100730 non-null  float64       \n",
      " 3   Price_Each        100730 non-null  float64       \n",
      " 4   Order_Date        100730 non-null  datetime64[ns]\n",
      " 5   Purchase_Address  100925 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(3), object(2)\n",
      "memory usage: 4.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order_ID</th>\n",
       "      <th>Product</th>\n",
       "      <th>Quantity_Ordered</th>\n",
       "      <th>Price_Each</th>\n",
       "      <th>Order_Date</th>\n",
       "      <th>Purchase_Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>222910.0</td>\n",
       "      <td>Apple Airpods Headphones</td>\n",
       "      <td>1.0</td>\n",
       "      <td>150.00</td>\n",
       "      <td>2026-07-19 16:51:00</td>\n",
       "      <td>389 South St, Atlanta, GA 30301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>222911.0</td>\n",
       "      <td>Flatscreen TV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300.00</td>\n",
       "      <td>2005-07-19 08:55:00</td>\n",
       "      <td>590 4th St, Seattle, WA 98101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>222912.0</td>\n",
       "      <td>AA Batteries (4-pack)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2029-07-19 12:41:00</td>\n",
       "      <td>861 Hill St, Atlanta, GA 30301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>222913.0</td>\n",
       "      <td>AA Batteries (4-pack)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2028-07-19 10:15:00</td>\n",
       "      <td>190 Ridge St, Atlanta, GA 30301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>222914.0</td>\n",
       "      <td>AAA Batteries (4-pack)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.99</td>\n",
       "      <td>2031-07-19 02:13:00</td>\n",
       "      <td>824 Forest St, Seattle, WA 98101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order_ID                   Product  Quantity_Ordered  Price_Each  \\\n",
       "0  222910.0  Apple Airpods Headphones               1.0      150.00   \n",
       "1  222911.0             Flatscreen TV               1.0      300.00   \n",
       "2  222912.0     AA Batteries (4-pack)               1.0        3.84   \n",
       "3  222913.0     AA Batteries (4-pack)               1.0        3.84   \n",
       "4  222914.0    AAA Batteries (4-pack)               5.0        2.99   \n",
       "\n",
       "           Order_Date                  Purchase_Address  \n",
       "0 2026-07-19 16:51:00   389 South St, Atlanta, GA 30301  \n",
       "1 2005-07-19 08:55:00     590 4th St, Seattle, WA 98101  \n",
       "2 2029-07-19 12:41:00    861 Hill St, Atlanta, GA 30301  \n",
       "3 2028-07-19 10:15:00   190 Ridge St, Atlanta, GA 30301  \n",
       "4 2031-07-19 02:13:00  824 Forest St, Seattle, WA 98101  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check shape of secondhalf_combined\n",
    "secondhalf_combined.shape\n",
    "\n",
    "#Check info of secondhalf_combined\n",
    "secondhalf_combined.info()\n",
    "\n",
    "#Check for first rows of heading\n",
    "secondhalf_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Order_ID</th>\n",
       "      <td>100730.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>271309.400338</td>\n",
       "      <td>222910.0</td>\n",
       "      <td>247141.25</td>\n",
       "      <td>271335.5</td>\n",
       "      <td>295475.75</td>\n",
       "      <td>319670.0</td>\n",
       "      <td>27917.487448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product</th>\n",
       "      <td>100925</td>\n",
       "      <td>20</td>\n",
       "      <td>USB-C Charging Cable</td>\n",
       "      <td>11951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quantity_Ordered</th>\n",
       "      <td>100730.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.124432</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.44642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price_Each</th>\n",
       "      <td>100730.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>183.043312</td>\n",
       "      <td>2.99</td>\n",
       "      <td>11.95</td>\n",
       "      <td>14.95</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>332.133484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Order_Date</th>\n",
       "      <td>100730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-09-06 10:53:12.888712192</td>\n",
       "      <td>2001-01-20 00:10:00</td>\n",
       "      <td>2008-11-19 20:50:00</td>\n",
       "      <td>2016-10-19 09:22:00</td>\n",
       "      <td>2024-07-19 13:24:00</td>\n",
       "      <td>2031-12-19 23:53:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Purchase_Address</th>\n",
       "      <td>100925</td>\n",
       "      <td>84781</td>\n",
       "      <td>Purchase Address</td>\n",
       "      <td>195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count unique                   top   freq  \\\n",
       "Order_ID          100730.0    NaN                   NaN    NaN   \n",
       "Product             100925     20  USB-C Charging Cable  11951   \n",
       "Quantity_Ordered  100730.0    NaN                   NaN    NaN   \n",
       "Price_Each        100730.0    NaN                   NaN    NaN   \n",
       "Order_Date          100730    NaN                   NaN    NaN   \n",
       "Purchase_Address    100925  84781      Purchase Address    195   \n",
       "\n",
       "                                           mean                  min  \\\n",
       "Order_ID                          271309.400338             222910.0   \n",
       "Product                                     NaN                  NaN   \n",
       "Quantity_Ordered                       1.124432                  1.0   \n",
       "Price_Each                           183.043312                 2.99   \n",
       "Order_Date        2016-09-06 10:53:12.888712192  2001-01-20 00:10:00   \n",
       "Purchase_Address                            NaN                  NaN   \n",
       "\n",
       "                                  25%                  50%  \\\n",
       "Order_ID                    247141.25             271335.5   \n",
       "Product                           NaN                  NaN   \n",
       "Quantity_Ordered                  1.0                  1.0   \n",
       "Price_Each                      11.95                14.95   \n",
       "Order_Date        2008-11-19 20:50:00  2016-10-19 09:22:00   \n",
       "Purchase_Address                  NaN                  NaN   \n",
       "\n",
       "                                  75%                  max           std  \n",
       "Order_ID                    295475.75             319670.0  27917.487448  \n",
       "Product                           NaN                  NaN           NaN  \n",
       "Quantity_Ordered                  1.0                  9.0       0.44642  \n",
       "Price_Each                      150.0               1700.0    332.133484  \n",
       "Order_Date        2024-07-19 13:24:00  2031-12-19 23:53:00           NaN  \n",
       "Purchase_Address                  NaN                  NaN           NaN  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Describe secondhalf_combined \n",
    "secondhalf_combined.describe(include='all').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order_ID            495\n",
      "Product             300\n",
      "Quantity_Ordered    495\n",
      "Price_Each          495\n",
      "Order_Date          495\n",
      "Purchase_Address    300\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(secondhalf_combined.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Insights from Secondhalf_combined**\n",
    "\n",
    "- The combined second half data has 101225 entries total 6 columns\n",
    "\n",
    "- Columns Order_ID, Quantity_Ordered, Price_Each, Order_Date have 495 missing values each and 300 missing values for Product and Purchase_Address.\n",
    "\n",
    "- Order date column must be cleaned and converted because it shows unrealistic future dates, such as 2031-12-19, indicate possible data entry errors.\n",
    "\n",
    "- Data types of order Id and quantity must be changed to int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Data Exploring and Cleaning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Order_ID                   Product  Quantity_Ordered  Price_Each  \\\n",
      "0  222910.0  Apple Airpods Headphones               1.0      150.00   \n",
      "1  222911.0             Flatscreen TV               1.0      300.00   \n",
      "2  222912.0     AA Batteries (4-pack)               1.0        3.84   \n",
      "3  222913.0     AA Batteries (4-pack)               1.0        3.84   \n",
      "4  222914.0    AAA Batteries (4-pack)               5.0        2.99   \n",
      "\n",
      "           Order_Date                  Purchase_Address  \n",
      "0 2026-07-19 16:51:00   389 South St, Atlanta, GA 30301  \n",
      "1 2005-07-19 08:55:00     590 4th St, Seattle, WA 98101  \n",
      "2 2029-07-19 12:41:00    861 Hill St, Atlanta, GA 30301  \n",
      "3 2028-07-19 10:15:00   190 Ridge St, Atlanta, GA 30301  \n",
      "4 2031-07-19 02:13:00  824 Forest St, Seattle, WA 98101  \n"
     ]
    }
   ],
   "source": [
    "# Drop rows'Order ID', 'Quantity Ordered', and 'Price Each'\n",
    "secondhalf_cleaned = secondhalf_combined.dropna(subset=['Order_ID', 'Quantity_Ordered', 'Price_Each'])\n",
    "\n",
    "\n",
    "#For other columns, you may want to fill missing data\n",
    "secondhalf_cleaned['Product'].fillna('Unknown', inplace=True)\n",
    "secondhalf_cleaned['Purchase_Address'].fillna('Unknown Address', inplace=True)\n",
    "print(secondhalf_cleaned.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows:\n",
      "       Order_ID                     Product  Quantity_Ordered  Price_Each  \\\n",
      "2880   225674.0  Bose SoundSport Headphones               1.0   99.989998   \n",
      "3580   226333.0      AAA Batteries (4-pack)               1.0    2.990000   \n",
      "3674   226421.0                Google Phone               1.0  600.000000   \n",
      "3784   226526.0      AAA Batteries (4-pack)               1.0    2.990000   \n",
      "3887   226625.0            Wired Headphones               1.0   11.990000   \n",
      "...         ...                         ...               ...         ...   \n",
      "96002  314675.0       AA Batteries (4-pack)               1.0    3.840000   \n",
      "96560  315204.0            Wired Headphones               1.0   11.990000   \n",
      "97348  315955.0             ThinkPad Laptop               1.0  999.989990   \n",
      "97575  316173.0      AAA Batteries (4-pack)               1.0    2.990000   \n",
      "99460  317971.0       AA Batteries (4-pack)               1.0    3.840000   \n",
      "\n",
      "               Order_Date                          Purchase_Address  \n",
      "2880  2006-07-19 09:28:00          470 Center St, Atlanta, GA 30301  \n",
      "3580  2005-07-19 09:33:00            947 West St, Seattle, WA 98101  \n",
      "3674  2028-07-19 17:21:00      162 14th St, San Francisco, CA 94016  \n",
      "3784  2002-07-19 18:05:00        926 Chestnut St, Atlanta, GA 30301  \n",
      "3887  2015-07-19 23:06:00    553 Willow St, San Francisco, CA 94016  \n",
      "...                   ...                                       ...  \n",
      "96002 2026-12-19 09:01:00      927 13th St, San Francisco, CA 94016  \n",
      "96560 2012-12-19 12:41:00       680 6th St, San Francisco, CA 94016  \n",
      "97348 2026-12-19 17:28:00        588 Chestnut St, Seattle, WA 98101  \n",
      "97575 2022-12-19 22:44:00         907 Sunset St, Portland, OR 97035  \n",
      "99460 2017-12-19 18:39:00  250 Chestnut St, San Francisco, CA 94016  \n",
      "\n",
      "[156 rows x 6 columns]\n",
      "Number of duplicate rows: 100730\n",
      "\n",
      "DataFrame after dropping duplicates:\n",
      "   Order_ID                   Product  Quantity_Ordered  Price_Each  \\\n",
      "0  222910.0  Apple Airpods Headphones               1.0      150.00   \n",
      "1  222911.0             Flatscreen TV               1.0      300.00   \n",
      "2  222912.0     AA Batteries (4-pack)               1.0        3.84   \n",
      "3  222913.0     AA Batteries (4-pack)               1.0        3.84   \n",
      "4  222914.0    AAA Batteries (4-pack)               5.0        2.99   \n",
      "\n",
      "           Order_Date                  Purchase_Address  \n",
      "0 2026-07-19 16:51:00   389 South St, Atlanta, GA 30301  \n",
      "1 2005-07-19 08:55:00     590 4th St, Seattle, WA 98101  \n",
      "2 2029-07-19 12:41:00    861 Hill St, Atlanta, GA 30301  \n",
      "3 2028-07-19 10:15:00   190 Ridge St, Atlanta, GA 30301  \n",
      "4 2031-07-19 02:13:00  824 Forest St, Seattle, WA 98101  \n",
      "\n",
      "Number of remaining duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "print(\"Duplicate rows:\")\n",
    "print(secondhalf_cleaned[secondhalf_cleaned.duplicated()])\n",
    "print(f\"Number of duplicate rows: {secondhalf_cleaned.shape[0]}\")\n",
    "\n",
    "# Drop duplicates based on 'Order_ID' and keep the first occurrence\n",
    "secondhalf_cleaned = secondhalf_cleaned.drop_duplicates(subset=['Order_ID'], keep='first')\n",
    "print(\"\\nDataFrame after dropping duplicates:\")\n",
    "print(secondhalf_cleaned.head())\n",
    "\n",
    "# Verify the removal of duplicates\n",
    "print(\"\\nNumber of remaining duplicates:\", secondhalf_cleaned.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 96761 entries, 0 to 101224\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   Order_ID          96761 non-null  int64         \n",
      " 1   Product           96761 non-null  object        \n",
      " 2   Quantity_Ordered  96761 non-null  int64         \n",
      " 3   Price_Each        96761 non-null  float64       \n",
      " 4   Order_Date        96761 non-null  datetime64[ns]\n",
      " 5   Purchase_Address  96761 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(1), int64(2), object(2)\n",
      "memory usage: 5.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Convert 'Order_ID' to integer\n",
    "secondhalf_cleaned['Order_ID'] = secondhalf_cleaned['Order_ID'].astype(int)\n",
    "\n",
    "# Convert 'Quantity_Ordered' to integer\n",
    "secondhalf_cleaned['Quantity_Ordered'] = secondhalf_cleaned['Quantity_Ordered'].astype(int)\n",
    "\n",
    "# Convert 'Order_Date' to datetime\n",
    "secondhalf_cleaned['Order_Date'] = pd.to_datetime(secondhalf_cleaned['Order_Date'], errors='coerce')\n",
    "\n",
    "# Verify the data types after conversion\n",
    "print(secondhalf_cleaned.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Merging of both Data sets (firsthalf_cleaned and secondhalf_cleaned)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame:\n",
      "   Order_ID                   Product  Quantity_Ordered  Price_Each  \\\n",
      "0    141234                    iPhone                 1      700.00   \n",
      "1    141235  Lightning Charging Cable                 1       14.95   \n",
      "2    141236          Wired Headphones                 2       11.99   \n",
      "3    141237          27in FHD Monitor                 1      149.99   \n",
      "4    141238          Wired Headphones                 1       11.99   \n",
      "\n",
      "           Order_Date                       Purchase_Address  \n",
      "0 2019-01-22 21:25:00        944 Walnut St, Boston, MA 02215  \n",
      "1 2019-01-28 14:15:00       185 Maple St, Portland, OR 97035  \n",
      "2 2019-01-17 13:33:00  538 Adams St, San Francisco, CA 94016  \n",
      "3 2019-01-05 20:33:00     738 10th St, Los Angeles, CA 90001  \n",
      "4 2019-01-25 11:59:00          387 10th St, Austin, TX 73301  \n"
     ]
    }
   ],
   "source": [
    "# For the first half (January to June), ensuring column names are consistent\n",
    "firsthalf_cleaned.rename(columns={\n",
    "    'Order ID': 'Order_ID',\n",
    "    'Quantity Ordered': 'Quantity_Ordered',\n",
    "    'Price Each': 'Price_Each',\n",
    "    'Order Date': 'Order_Date',\n",
    "    'Purchase Address': 'Purchase_Address'\n",
    "}, inplace=True)\n",
    "\n",
    "# Now concatenate the datasets\n",
    "df_combined = pd.concat([firsthalf_cleaned, secondhalf_cleaned], ignore_index=True)\n",
    "\n",
    "# Show the first few rows to confirm the data is concatenated properly\n",
    "print(\"Combined DataFrame:\")\n",
    "print(df_combined.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178438 entries, 0 to 178437\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count   Dtype         \n",
      "---  ------            --------------   -----         \n",
      " 0   Order_ID          178437 non-null  Int64         \n",
      " 1   Product           178438 non-null  object        \n",
      " 2   Quantity_Ordered  178437 non-null  Int64         \n",
      " 3   Price_Each        178437 non-null  float64       \n",
      " 4   Order_Date        178437 non-null  datetime64[ns]\n",
      " 5   Purchase_Address  178438 non-null  object        \n",
      "dtypes: Int64(2), datetime64[ns](1), float64(1), object(2)\n",
      "memory usage: 8.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_combined.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Further Exploring and Cleaning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in column 'Order_ID':\n",
      "[295665. 295666. 295667. ... 319668. 319669. 319670.]\n",
      "\n",
      "Unique values in column 'Product':\n",
      "['Macbook Pro Laptop' 'LG Washing Machine' 'USB-C Charging Cable'\n",
      " '27in FHD Monitor' 'AA Batteries (4-pack)' 'Bose SoundSport Headphones'\n",
      " 'AAA Batteries (4-pack)' 'ThinkPad Laptop' 'Lightning Charging Cable'\n",
      " 'Google Phone' 'Wired Headphones' 'Apple Airpods Headphones'\n",
      " 'Vareebadd Phone' 'iPhone' '20in Monitor' '34in Ultrawide Monitor'\n",
      " 'Flatscreen TV' '27in 4K Gaming Monitor' 'Product' None 'LG Dryer']\n",
      "\n",
      "Unique values in column 'Quantity_Ordered':\n",
      "[ 1.  2.  4.  3. nan  7.  5.  6.]\n",
      "\n",
      "Unique values in column 'Price_Each':\n",
      "[1700.          600.           11.94999981  149.99000549    3.83999991\n",
      "   99.98999786    2.99000001  999.98999023   14.94999981   11.98999977\n",
      "  150.          400.          700.          109.98999786  379.98999023\n",
      "  300.          389.98999023           nan]\n",
      "\n",
      "Unique values in column 'Order_Date':\n",
      "<DatetimeArray>\n",
      "['2030-12-19 00:01:00', '2029-12-19 07:03:00', '2012-12-19 18:21:00',\n",
      " '2022-12-19 15:13:00', '2018-12-19 12:38:00', '2031-12-19 22:58:00',\n",
      " '2016-12-19 15:10:00', '2013-12-19 09:29:00', '2015-12-19 23:26:00',\n",
      " '2028-12-19 11:51:00',\n",
      " ...\n",
      " '2003-12-19 05:50:00', '2023-12-19 14:08:00', '2013-12-19 07:25:00',\n",
      " '2011-12-19 21:24:00', '2007-12-19 08:25:00', '2030-12-19 01:06:00',\n",
      " '2011-12-19 20:58:00', '2001-12-19 12:01:00', '2009-12-19 06:43:00',\n",
      " '2003-12-19 10:39:00']\n",
      "Length: 17306, dtype: datetime64[ns]\n",
      "\n",
      "Unique values in column 'Purchase_Address':\n",
      "['136 Church St, New York City, NY 10001'\n",
      " '562 2nd St, New York City, NY 10001'\n",
      " '277 Main St, New York City, NY 10001' ...\n",
      " '273 Wilson St, Seattle, WA 98101' '778 River St, Dallas, TX 75001'\n",
      " '747 Chestnut St, Los Angeles, CA 90001']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop through each column and print unique values\n",
    "for column in df_combined.columns:\n",
    "    unique_values = df[column].unique()\n",
    "    print(f\"Unique values in column '{column}':\")\n",
    "    print(unique_values)\n",
    "    print()  # Blank line for better readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order_ID            1\n",
      "Product             0\n",
      "Quantity_Ordered    1\n",
      "Price_Each          1\n",
      "Order_Date          1\n",
      "Purchase_Address    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in critical columns\n",
    "print(df_combined.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates based on Order_ID\n",
    "#duplicates = df_combined[df_combined.duplicated(subset='Order_ID')]\n",
    "#print(f\"Number of duplicates: {duplicates.shape[0]}\")\n",
    "\n",
    "# If duplicates exist, drop them\n",
    "#df_combined.drop_duplicates(subset='Order_ID', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order_ID            1\n",
      "Product             0\n",
      "Quantity_Ordered    1\n",
      "Price_Each          1\n",
      "Order_Date          1\n",
      "Purchase_Address    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in critical columns\n",
    "print(df_combined.isnull().sum())\n",
    "\n",
    "# Drop rows where critical columns are null\n",
    "#df_combined.dropna(subset=['Order_ID', 'Quantity_Ordered', 'Price_Each', 'Order_Date'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are invalid dates in the 'Order Date' column.\n"
     ]
    }
   ],
   "source": [
    "# Check for any NaT values (invalid dates)\n",
    "if df_combined['Order_Date'].isna().any():\n",
    "    print(\"There are invalid dates in the 'Order Date' column.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Order Id Column clean*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[295665. 295666. 295667. ... 319668. 319669. 319670.]\n",
      "Number of duplicated Order_IDs: 1110\n",
      "DataFrame after removing duplicate Order_ID rows:\n",
      "       Order_ID                     Product  Quantity_Ordered   Price_Each  \\\n",
      "0      295665.0          Macbook Pro Laptop               1.0  1700.000000   \n",
      "1      295666.0          LG Washing Machine               1.0   600.000000   \n",
      "2      295667.0        USB-C Charging Cable               1.0    11.950000   \n",
      "3      295668.0            27in FHD Monitor               1.0   149.990005   \n",
      "4      295669.0        USB-C Charging Cable               1.0    11.950000   \n",
      "...         ...                         ...               ...          ...   \n",
      "25112  319666.0    Lightning Charging Cable               1.0    14.950000   \n",
      "25113  319667.0       AA Batteries (4-pack)               2.0     3.840000   \n",
      "25114  319668.0             Vareebadd Phone               1.0   400.000000   \n",
      "25115  319669.0            Wired Headphones               1.0    11.990000   \n",
      "25116  319670.0  Bose SoundSport Headphones               1.0    99.989998   \n",
      "\n",
      "               Order_Date                        Purchase_Address  \n",
      "0     2030-12-19 00:01:00  136 Church St, New York City, NY 10001  \n",
      "1     2029-12-19 07:03:00     562 2nd St, New York City, NY 10001  \n",
      "2     2012-12-19 18:21:00    277 Main St, New York City, NY 10001  \n",
      "3     2022-12-19 15:13:00     410 6th St, San Francisco, CA 94016  \n",
      "4     2018-12-19 12:38:00           43 Hill St, Atlanta, GA 30301  \n",
      "...                   ...                                     ...  \n",
      "25112 2011-12-19 20:58:00  14 Madison St, San Francisco, CA 94016  \n",
      "25113 2001-12-19 12:01:00    549 Willow St, Los Angeles, CA 90001  \n",
      "25114 2009-12-19 06:43:00        273 Wilson St, Seattle, WA 98101  \n",
      "25115 2003-12-19 10:39:00          778 River St, Dallas, TX 75001  \n",
      "25116 2021-12-19 21:45:00  747 Chestnut St, Los Angeles, CA 90001  \n",
      "\n",
      "[24007 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Using pandas' unique() function\n",
    "unique_values = df['Order_ID'].unique()\n",
    "print(unique_values)\n",
    "\n",
    "\n",
    "# Count the number of duplicated Order_IDs\n",
    "num_duplicates = df['Order_ID'].duplicated().sum()\n",
    "\n",
    "print(f\"Number of duplicated Order_IDs: {num_duplicates}\")\n",
    "\n",
    "\n",
    "# Drop duplicate Order_ID rows, keeping the first occurrence\n",
    "df_unique = df.drop_duplicates(subset='Order_ID', keep='first')\n",
    "\n",
    "# Verify the result\n",
    "print(\"DataFrame after removing duplicate Order_ID rows:\")\n",
    "print(df_unique)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Products' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mProducts\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Using pandas' unique() function\u001b[39;00m\n\u001b[0;32m      3\u001b[0m unique_values \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProduct\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Products' is not defined"
     ]
    }
   ],
   "source": [
    "Products\n",
    "# Using pandas' unique() function\n",
    "unique_values = df['Product'].unique()\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qty Ordered \n",
    "\n",
    "# Step 1: Convert 'Quantity_Ordered' to numeric, coercing non-numeric values to NaN\n",
    "df['Quantity_Ordered'] = pd.to_numeric(df['Quantity_Ordered'], errors='coerce')\n",
    "\n",
    "# Step 2: Drop NaN values that result from invalid conversions\n",
    "df = df.dropna(subset=['Quantity_Ordered'])\n",
    "\n",
    "# Step 3: Convert the column to integers\n",
    "df['Quantity_Ordered'] = df['Quantity_Ordered'].astype(int)\n",
    "\n",
    "# Step 4: Get the unique values\n",
    "unique_values = df['Quantity_Ordered'].unique()\n",
    "\n",
    "# Step 5: Print the unique integer values\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price each\n",
    "# Using pandas' unique() function\n",
    "unique_values = df['Price_Each'].unique()\n",
    "print(unique_values)\n",
    "\n",
    "\n",
    "# Clean the 'Price_Each' column\n",
    "df['Price_Each'] = pd.to_numeric(df['Price_Each'], errors='coerce')  # Convert to numeric, forcing errors to NaN\n",
    "\n",
    "# Drop NaN values\n",
    "df_cleaned = df.dropna(subset=['Price_Each'])\n",
    "\n",
    "# Round to 2 decimal places\n",
    "df_cleaned['Price_Each'] = df_cleaned['Price_Each'].round(2)\n",
    "\n",
    "# Check the unique values after cleaning\n",
    "unique_values_cleaned = df_cleaned['Price_Each'].unique()\n",
    "print(unique_values_cleaned)\n",
    "\n",
    "# Round values in the 'Price_Each' column to 2 decimal places\n",
    "df['Price_Each'] = df['Price_Each'].round(2)\n",
    "\n",
    "# Verify the result\n",
    "print(df['Price_Each'].head())\n",
    "\n",
    "\n",
    "\n",
    "# Ensure that 'Quantity_Ordered' and 'Price_Each' are numeric\n",
    "df_unique['Quantity_Ordered'] = pd.to_numeric(df_unique['Quantity_Ordered'], errors='coerce')\n",
    "df['Price_Each'] = pd.to_numeric(df_unique['Price_Each'], errors='coerce')\n",
    "\n",
    "# Create a new column 'Sales' by multiplying 'Quantity_Ordered' and 'Price_Each'\n",
    "df_unique['Sales'] = df_unique['Quantity_Ordered'] * df_unique['Price_Each']\n",
    "\n",
    "# Verify the result\n",
    "print(df_unique[['Quantity_Ordered', 'Price_Each', 'Sales']].head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order date \n",
    "# Convert 'Order Date' to datetime and handle errors\n",
    "df_combined['Order_Date'] = pd.to_datetime(df_combined['Order_Date'], format='%m/%d/%y %H:%M', errors='coerce')\n",
    "\n",
    "# Check for any NaT values (invalid dates)\n",
    "if df_combined['Order_Date'].isna().any():\n",
    "    print(\"There are invalid dates in the 'Order_Date' column.\")\n",
    "\n",
    "# Optionally, handle invalid dates (e.g., fill with a default date or leave as NaT)\n",
    "df_combined['Order_Date'] = df_combined['Order_Date'].fillna(pd.Timestamp('1970-01-01 00:00:00'))  # Example: fill with a default date\n",
    "\n",
    "# Format only the valid dates\n",
    "df_combined['Order_Date'] = df_combined['Order_Date'].apply(lambda x: x.strftime('%Y-%m-%d %H:%M:%S.%f') if pd.notna(x) else None)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_combined)\n",
    "\n",
    "\n",
    "# Ensure that Order_Date is in datetime format\n",
    "df_unique['Order_Date'] = pd.to_datetime(df_unique['Order_Date'])\n",
    "\n",
    "# Create a new column 'Month' by extracting the month from 'Order_Date'\n",
    "df_unique['Month'] = df_unique['Order_Date'].dt.month\n",
    "\n",
    "# Verify the result\n",
    "print(df_unique[['Order_Date', 'Month']].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase address \n",
    "\n",
    "# Using pandas' unique() function\n",
    "unique_values = df['Purchase_Address'].unique()\n",
    "print(unique_values)\n",
    "\n",
    "\n",
    "# Split the Purchase_Address column and extract the City\n",
    "\n",
    "# Define a function to extract city from the address\n",
    "def get_city(address):\n",
    "    return address.split(\",\")[1].strip()\n",
    "\n",
    "# Apply the function to create a new 'City' column\n",
    "df_unique['City'] = df_unique['Purchase_Address'].apply(get_city)\n",
    "\n",
    "# Display the updated DataFrame with the new 'City' column\n",
    "print(df_unique.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **General Insights**\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Preparation** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Modelling and Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Deployment**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
